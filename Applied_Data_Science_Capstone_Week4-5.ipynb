{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "## Introduction: Rental Housing in San Francisco\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n    \n1. [Problem and Discussion](#0)<br>\n2. [Description of Data and How it will be Used](#1)<br>\n</div>\n<hr>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 1. Problem and Discussion<a id=\"0\"></a>\n\nOften relocation is a time consuming process. Finding affordable housing with safe neighborhoods and prefered venues is a big challenge.  Data science can save time for finding and meeting such criteria by providing interactive visual tools through Jupyter notebook.  A Goal of this project is to provide such a sample in San Francisco utilizing  **Folium** library to make visual segmentation and clustering data in a map.  This notebook allows users to tweek few parameters and shows crime rate in neighborhoods, rental price ranges and venues on interactive maps.<br><br>\nThis project can help rentees considering moving to San Francisco or renters deciding reasonable rents since interactive visual aids can quickly allow users to see intuitive and interactive visual infromation. The use of FourSquare data and mapping techniques combined with data analysis will help providing clustered venues along with rents and crime rate in a single map. Lastly, this project is a good practical case toward the development of Data Science skills.<br>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### 2. Dicription of Data and How it will be Used<a id=\"1\"></a>\n<br>\n\nIn this jupyter notebook, main focal area is set to San Francisco.  This notebook will use geojson data from DataSF (https://data.sfgov.org/api/geospatial/pty2-tcw4?method=export&format=GeoJSON) for geographical information and police department incident report from DataSF (https://data.sfgov.org/api/views/wg3w-h783/rows.csv?accessType=DOWNLOAD) for crime statistics and finally use python-craigslist to retrieve set of most recent posts on interactive map.  The raw data from craigslist is programatically scraped.  The data will generate statistics and interactive visual aids for users.<br><br>\nUse Foursquare and geopy data to map top 10 venues for all San Francisco neighborhoods and clustered in groups ( as per Course LAB). Use foursquare and geopy data to map the location of available rental housings and crime rates, separately and on top of the above clustered map in order to identify the venues.  The markers of rental housing display the rents and URL to the posts in the popups. Alternatively Boxplot and Choropleth Maps shows rents statistics and average rents respectively to give a general price trend in the neighborhoods. "
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "## Table of Contents\n\n<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n\n1. [Exploring Datasets with *p*andas](#3)<br>\n2. [Downloading and Prepping Data](#4)<br>\n3. [Introduction to Folium](#5) <br>\n4. [Map with Markers](#6) <br>\n5. [Choropleth Maps](#8) <br>\n    * Introduction where you discuss the business problem and who would be interested in this project.\n    * Data where you describe the data that will be used to solve the problem and the source of the data.\n    * Methodology section which represents the main component of the report where you discuss and describe any exploratory data analysis that you did, any inferential statistical testing that you performed, if any, and what machine learnings were used and why.\n    * Results section where you discuss the results.\n    * Discussion section where you discuss any observations you noted and any recommendations you can make based on the results.\n    * Conclusion section where you conclude the report.\n</div>\n<hr>"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "# Exploring Datasets with *pandas* and Matplotlib<a id=\"3\"></a>\n\nDatasets: \n\n1. San Francisco Police Department Incidents from the year 2018 to present - [Police Department Incidents](https://data.sfgov.org/Public-Safety/Police-Department-Incident-Reports-2018-to-Present/wg3w-h783) from San Francisco public data portal. Incidents derived from San Francisco Police Department (SFPD) Crime Incident Reporting system. Updated daily, showing data for the 2018 to current.\n\n2. San Francisco Neighborhoods - [San Francisco Neighborhoods](https://data.sfgov.org/Geographic-Locations-and-Boundaries/SF-Find-Neighborhoods/pty2-tcw4) from San Francisco public data portal. Neighborhood boundaries that were defined in 2006 by the Mayor's Office of Neighborhood Services for use with the SF Find tool: [SF Planning](http://propertymap.sfplanning.org/?name=sffind). All boundaries are for the purpose of defining general locations of neighborhoods for the SF FIND application only, and as such they are not \"hard\" lines of demarcation"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "# Downloading and Prepping Data <a id=\"4\"></a>"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "Import Primary Modules:"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Requirement already satisfied: geopy in /opt/conda/envs/Python36/lib/python3.6/site-packages (1.18.1)\nRequirement already satisfied: geographiclib<2,>=1.49 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from geopy) (1.49)\nRequirement already satisfied: folium in /opt/conda/envs/Python36/lib/python3.6/site-packages (0.10.1)\nRequirement already satisfied: requests in /opt/conda/envs/Python36/lib/python3.6/site-packages (from folium) (2.21.0)\nRequirement already satisfied: jinja2>=2.9 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from folium) (2.10)\nRequirement already satisfied: branca>=0.3.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from folium) (0.4.0)\nRequirement already satisfied: numpy in /opt/conda/envs/Python36/lib/python3.6/site-packages (from folium) (1.15.4)\nRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->folium) (2.8)\nRequirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->folium) (1.24.1)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->folium) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->folium) (2019.11.28)\nRequirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from jinja2>=2.9->folium) (1.1.0)\nRequirement already satisfied: six in /opt/conda/envs/Python36/lib/python3.6/site-packages (from branca>=0.3.0->folium) (1.12.0)\nRequirement already satisfied: lxml in /opt/conda/envs/Python36/lib/python3.6/site-packages (4.3.1)\nRequirement already up-to-date: python-craigslist in /opt/conda/envs/Python36/lib/python3.6/site-packages (1.0.8)\nRequirement already satisfied, skipping upgrade: beautifulsoup4 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from python-craigslist) (4.7.1)\nRequirement already satisfied, skipping upgrade: requests in /opt/conda/envs/Python36/lib/python3.6/site-packages (from python-craigslist) (2.21.0)\nRequirement already satisfied, skipping upgrade: six in /opt/conda/envs/Python36/lib/python3.6/site-packages (from python-craigslist) (1.12.0)\nRequirement already satisfied, skipping upgrade: soupsieve>=1.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from beautifulsoup4->python-craigslist) (1.7.1)\nRequirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->python-craigslist) (2019.11.28)\nRequirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->python-craigslist) (1.24.1)\nRequirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->python-craigslist) (2.8)\nRequirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from requests->python-craigslist) (3.0.4)\nLibraries imported.\n"
                }
            ],
            "source": "import numpy as np # library to handle data in a vectorized manner\nimport pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # library to handle JSON files\n\n# !conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\n!pip install geopy\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n# !conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\n!pip install folium\nimport folium # map rendering library\n\n# !conda install -c conda-forge lxml --yes\n!pip install lxml\n!pip install python-craigslist --upgrade\n\nprint('Libraries imported.')"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "# Introduction to Folium <a id=\"5\"></a>"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "Folium is a powerful Python library that helps you create several types of Leaflet maps. The fact that the Folium results are interactive makes this library very useful for dashboard building."
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "# Maps with Markers <a id=\"6\"></a>\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "Let's download and import the data on police department incidents using *pandas* `read_csv()` method."
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "Download the dataset and read it into a *pandas* dataframe:\nThen drop raws which miss essential data."
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting wget\n  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\nBuilding wheels for collected packages: wget\n  Building wheel for wget (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/dsxuser/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\nSuccessfully built wget\nInstalling collected packages: wget\nSuccessfully installed wget-3.2\n"
                }
            ],
            "source": "!pip install wget\n!wget -q -O 'SF_Find_Neighborhoods.geojson' https://data.sfgov.org/api/geospatial/pty2-tcw4?method=export&format=GeoJSON\n!wget -q -O 'Police_Department_Incident_Reports__2018_to_Present.csv' https://data.sfgov.org/api/views/wg3w-h783/rows.csv?accessType=DOWNLOAD"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "button": false,
                "jupyter": {
                    "outputs_hidden": false
                },
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Dataset downloaded and read into a pandas dataframe!\n(234195, 36)\n"
                },
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Incident Datetime</th>\n      <th>Incident Date</th>\n      <th>Incident Time</th>\n      <th>Incident Year</th>\n      <th>Incident Day of Week</th>\n      <th>Report Datetime</th>\n      <th>Row ID</th>\n      <th>Incident ID</th>\n      <th>Incident Number</th>\n      <th>CAD Number</th>\n      <th>Report Type Code</th>\n      <th>Report Type Description</th>\n      <th>Filed Online</th>\n      <th>Incident Code</th>\n      <th>Category</th>\n      <th>Incident Subcategory</th>\n      <th>Incident Description</th>\n      <th>Resolution</th>\n      <th>Intersection</th>\n      <th>CNN</th>\n      <th>Police District</th>\n      <th>Neighborhood</th>\n      <th>Supervisor District</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>point</th>\n      <th>SF Find Neighborhoods</th>\n      <th>Current Police Districts</th>\n      <th>Current Supervisor Districts</th>\n      <th>Analysis Neighborhoods</th>\n      <th>HSOC Zones as of 2018-06-05</th>\n      <th>OWED Public Spaces</th>\n      <th>Central Market/Tenderloin Boundary Polygon - Updated</th>\n      <th>Parks Alliance CPSI (27+TL sites)</th>\n      <th>ESNCAG - Boundary File</th>\n      <th>Areas of Vulnerability, 2016</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020/02/03 02:45:00 PM</td>\n      <td>2020/02/03</td>\n      <td>14:45</td>\n      <td>2020.0</td>\n      <td>Monday</td>\n      <td>2020/02/03 05:50:00 PM</td>\n      <td>8.988168e+10</td>\n      <td>898816.0</td>\n      <td>200085557.0</td>\n      <td>200342870.0</td>\n      <td>II</td>\n      <td>Initial</td>\n      <td>NaN</td>\n      <td>75000.0</td>\n      <td>Missing Person</td>\n      <td>Missing Person</td>\n      <td>Found Person</td>\n      <td>Open or Active</td>\n      <td>20TH AVE \\ WINSTON DR</td>\n      <td>33719000.0</td>\n      <td>Taraval</td>\n      <td>Lakeshore</td>\n      <td>7.0</td>\n      <td>37.7269</td>\n      <td>-122.476039</td>\n      <td>POINT (-122.47603947349434 37.72694991292525)</td>\n      <td>41.0</td>\n      <td>10.0</td>\n      <td>8.0</td>\n      <td>16.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020/02/03 03:45:00 AM</td>\n      <td>2020/02/03</td>\n      <td>03:45</td>\n      <td>2020.0</td>\n      <td>Monday</td>\n      <td>2020/02/03 03:45:00 AM</td>\n      <td>8.986071e+10</td>\n      <td>898607.0</td>\n      <td>200083749.0</td>\n      <td>200340316.0</td>\n      <td>II</td>\n      <td>Initial</td>\n      <td>NaN</td>\n      <td>11012.0</td>\n      <td>Stolen Property</td>\n      <td>Stolen Property</td>\n      <td>Stolen Property, Possession with Knowledge, Re...</td>\n      <td>Cite or Arrest Adult</td>\n      <td>24TH ST \\ SHOTWELL ST</td>\n      <td>24064000.0</td>\n      <td>Mission</td>\n      <td>Mission</td>\n      <td>9.0</td>\n      <td>37.7524</td>\n      <td>-122.415172</td>\n      <td>POINT (-122.41517229045435 37.752439644389675)</td>\n      <td>53.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>20.0</td>\n      <td>3.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020/02/03 10:00:00 AM</td>\n      <td>2020/02/03</td>\n      <td>10:00</td>\n      <td>2020.0</td>\n      <td>Monday</td>\n      <td>2020/02/03 10:06:00 AM</td>\n      <td>8.986726e+10</td>\n      <td>898672.0</td>\n      <td>200084060.0</td>\n      <td>200340808.0</td>\n      <td>II</td>\n      <td>Initial</td>\n      <td>NaN</td>\n      <td>64015.0</td>\n      <td>Non-Criminal</td>\n      <td>Other</td>\n      <td>Aided Case, Injured or Sick Person</td>\n      <td>Open or Active</td>\n      <td>MARKET ST \\ POWELL ST</td>\n      <td>34016000.0</td>\n      <td>Tenderloin</td>\n      <td>Financial District/South Beach</td>\n      <td>3.0</td>\n      <td>37.7846</td>\n      <td>-122.407337</td>\n      <td>POINT (-122.40733704162238 37.784560141211806)</td>\n      <td>19.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>35.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020/01/05 12:00:00 AM</td>\n      <td>2020/01/05</td>\n      <td>00:00</td>\n      <td>2020.0</td>\n      <td>Sunday</td>\n      <td>2020/02/03 04:09:00 PM</td>\n      <td>8.987737e+10</td>\n      <td>898773.0</td>\n      <td>200085193.0</td>\n      <td>200342341.0</td>\n      <td>II</td>\n      <td>Initial</td>\n      <td>NaN</td>\n      <td>68020.0</td>\n      <td>Miscellaneous Investigation</td>\n      <td>Miscellaneous Investigation</td>\n      <td>Miscellaneous Investigation</td>\n      <td>Open or Active</td>\n      <td>PINE ST \\ DIVISADERO ST</td>\n      <td>26643000.0</td>\n      <td>Richmond</td>\n      <td>Pacific Heights</td>\n      <td>2.0</td>\n      <td>37.7871</td>\n      <td>-122.440250</td>\n      <td>POINT (-122.44024995765258 37.78711245591735)</td>\n      <td>103.0</td>\n      <td>4.0</td>\n      <td>6.0</td>\n      <td>30.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2020/02/03 08:36:00 AM</td>\n      <td>2020/02/03</td>\n      <td>08:36</td>\n      <td>2020.0</td>\n      <td>Monday</td>\n      <td>2020/02/03 08:36:00 AM</td>\n      <td>8.987627e+10</td>\n      <td>898762.0</td>\n      <td>200083909.0</td>\n      <td>200340826.0</td>\n      <td>II</td>\n      <td>Initial</td>\n      <td>NaN</td>\n      <td>68020.0</td>\n      <td>Miscellaneous Investigation</td>\n      <td>Miscellaneous Investigation</td>\n      <td>Miscellaneous Investigation</td>\n      <td>Open or Active</td>\n      <td>FRONT ST \\ JACKSON ST</td>\n      <td>24697000.0</td>\n      <td>Central</td>\n      <td>Financial District/South Beach</td>\n      <td>3.0</td>\n      <td>37.7969</td>\n      <td>-122.399508</td>\n      <td>POINT (-122.39950750040278 37.796926429317054)</td>\n      <td>77.0</td>\n      <td>6.0</td>\n      <td>3.0</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "        Incident Datetime Incident Date Incident Time  Incident Year  \\\n0  2020/02/03 02:45:00 PM    2020/02/03         14:45         2020.0   \n1  2020/02/03 03:45:00 AM    2020/02/03         03:45         2020.0   \n2  2020/02/03 10:00:00 AM    2020/02/03         10:00         2020.0   \n4  2020/01/05 12:00:00 AM    2020/01/05         00:00         2020.0   \n5  2020/02/03 08:36:00 AM    2020/02/03         08:36         2020.0   \n\n  Incident Day of Week         Report Datetime        Row ID  Incident ID  \\\n0               Monday  2020/02/03 05:50:00 PM  8.988168e+10     898816.0   \n1               Monday  2020/02/03 03:45:00 AM  8.986071e+10     898607.0   \n2               Monday  2020/02/03 10:06:00 AM  8.986726e+10     898672.0   \n4               Sunday  2020/02/03 04:09:00 PM  8.987737e+10     898773.0   \n5               Monday  2020/02/03 08:36:00 AM  8.987627e+10     898762.0   \n\n   Incident Number   CAD Number Report Type Code Report Type Description  \\\n0      200085557.0  200342870.0               II                 Initial   \n1      200083749.0  200340316.0               II                 Initial   \n2      200084060.0  200340808.0               II                 Initial   \n4      200085193.0  200342341.0               II                 Initial   \n5      200083909.0  200340826.0               II                 Initial   \n\n  Filed Online  Incident Code                     Category  \\\n0          NaN        75000.0               Missing Person   \n1          NaN        11012.0              Stolen Property   \n2          NaN        64015.0                 Non-Criminal   \n4          NaN        68020.0  Miscellaneous Investigation   \n5          NaN        68020.0  Miscellaneous Investigation   \n\n          Incident Subcategory  \\\n0               Missing Person   \n1              Stolen Property   \n2                        Other   \n4  Miscellaneous Investigation   \n5  Miscellaneous Investigation   \n\n                                Incident Description            Resolution  \\\n0                                       Found Person        Open or Active   \n1  Stolen Property, Possession with Knowledge, Re...  Cite or Arrest Adult   \n2                 Aided Case, Injured or Sick Person        Open or Active   \n4                        Miscellaneous Investigation        Open or Active   \n5                        Miscellaneous Investigation        Open or Active   \n\n              Intersection         CNN Police District  \\\n0    20TH AVE \\ WINSTON DR  33719000.0         Taraval   \n1    24TH ST \\ SHOTWELL ST  24064000.0         Mission   \n2    MARKET ST \\ POWELL ST  34016000.0      Tenderloin   \n4  PINE ST \\ DIVISADERO ST  26643000.0        Richmond   \n5    FRONT ST \\ JACKSON ST  24697000.0         Central   \n\n                     Neighborhood  Supervisor District Latitude   Longitude  \\\n0                       Lakeshore                  7.0  37.7269 -122.476039   \n1                         Mission                  9.0  37.7524 -122.415172   \n2  Financial District/South Beach                  3.0  37.7846 -122.407337   \n4                 Pacific Heights                  2.0  37.7871 -122.440250   \n5  Financial District/South Beach                  3.0  37.7969 -122.399508   \n\n                                            point  SF Find Neighborhoods  \\\n0   POINT (-122.47603947349434 37.72694991292525)                   41.0   \n1  POINT (-122.41517229045435 37.752439644389675)                   53.0   \n2  POINT (-122.40733704162238 37.784560141211806)                   19.0   \n4   POINT (-122.44024995765258 37.78711245591735)                  103.0   \n5  POINT (-122.39950750040278 37.796926429317054)                   77.0   \n\n   Current Police Districts  Current Supervisor Districts  \\\n0                      10.0                           8.0   \n1                       3.0                           2.0   \n2                       5.0                           3.0   \n4                       4.0                           6.0   \n5                       6.0                           3.0   \n\n   Analysis Neighborhoods  HSOC Zones as of 2018-06-05  OWED Public Spaces  \\\n0                    16.0                          NaN                 NaN   \n1                    20.0                          3.0                 NaN   \n2                     8.0                          NaN                35.0   \n4                    30.0                          NaN                 NaN   \n5                     8.0                          NaN                 NaN   \n\n   Central Market/Tenderloin Boundary Polygon - Updated  \\\n0                                                NaN      \n1                                                NaN      \n2                                                NaN      \n4                                                NaN      \n5                                                NaN      \n\n   Parks Alliance CPSI (27+TL sites)  ESNCAG - Boundary File  \\\n0                                NaN                     NaN   \n1                                NaN                     NaN   \n2                                NaN                     NaN   \n4                                NaN                     NaN   \n5                                NaN                     NaN   \n\n   Areas of Vulnerability, 2016  \n0                           2.0  \n1                           2.0  \n2                           2.0  \n4                           1.0  \n5                           1.0  "
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_incidents = pd.read_csv('Police_Department_Incident_Reports__2018_to_Present.csv')\nprint('Dataset downloaded and read into a pandas dataframe!')\n\ndf_incidents.rename(columns={'Incident Category':'Category','Analysis Neighborhood':'Neighborhood'},inplace=True)\n\nrows = df_incidents[( pd.isna(df_incidents.Neighborhood))].index\ndf_incidents.drop(rows, inplace=True)\nprint(df_incidents.shape)\ndf_incidents.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "Let's find out how many entries there are in our dataset."
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {
                "button": false,
                "jupyter": {
                    "outputs_hidden": false
                },
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "(234195, 36)"
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df_incidents.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "Find San Francisco coordinate."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "address = 'San Francisco, USA'\n\ngeolocator = Nominatim(user_agent=\"ny_explorer\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinate of San Francisco are {}, {}.'.format(latitude, longitude))"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "Incidents are counted for each neighborhood for displaying the crime rate in the map later.  Load the the latest neighborhood geomery information into data frame to map the crime rate."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# print(df_incidents.head())\ndf_incidents['Count'] = df_incidents.sum(axis=1)\ndf_incidents['Count'] = 1\ndfc = df_incidents[['Neighborhood','Count']]\ndf_pd = dfc.groupby(['Neighborhood'],as_index= False).sum()\nprint(df_pd)\n\nimport json # library to handle JSON files\n\nwith open('SF_Find_Neighborhoods.geojson') as json_data:\n    sf_data = json.load(json_data)\n    \nneighborhoods_data = sf_data['features']\nneighborhoods_data[0]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Find the centroid of polygons in geojson\ndef centroid(vertexes):\n     _x_list = [vertex [0] for vertex in vertexes]\n     _y_list = [vertex [1] for vertex in vertexes]\n     _len = len(vertexes)\n     _x = sum(_x_list) / _len\n     _y = sum(_y_list) / _len\n     return(_x, _y)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The next task is essentially transforming this data of nested Python dictionaries into a *pandas* dataframe. So let's start by creating an empty dataframe."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# define the dataframe columns\ncolumn_names = ['Borough', 'Neighborhood', 'Latitude', 'Longitude'] \n\n# instantiate the dataframe\nneighborhoods = pd.DataFrame(columns=column_names)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "for data in neighborhoods_data:\n    borough = data['properties']['name'] \n    neighborhood_name = data['properties']['name']\n        \n    neighborhood_latlon = data['geometry']['coordinates'][0][0]\n    p = centroid(neighborhood_latlon)\n    # print(p)\n    neighborhood_lat = p[1]\n    neighborhood_lon = p[0]\n    \n    neighborhoods = neighborhoods.append({'Borough': borough,\n                                          'Neighborhood': neighborhood_name,\n                                          'Latitude': neighborhood_lat,\n                                          'Longitude': neighborhood_lon}, ignore_index=True)\n    \n# neighborhoods[{'Neighborhood', 'Latitude','Longitude'}]\nneighborhoods.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Set up credential to retreve venues from 4 squre."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "button": false,
                "jupyter": {
                    "outputs_hidden": false
                },
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "outputs": [],
            "source": "CLIENT_ID = 'YZH5ISDMNB4IAFJC1B3I4I4Q2XJVMP5D4DRRYP5PI3P2SJHI' # your Foursquare ID\nCLIENT_SECRET = '2WMSASM4CJJ5IMNE014OQBW1FGL52BVRAE3TU4GSBKLAWR25' # your Foursquare Secret\nVERSION = '20180605' # Foursquare API version\n\nprint('Your credentails:')\nprint('CLIENT_ID: ' + CLIENT_ID)\nprint('CLIENT_SECRET:' + CLIENT_SECRET)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "neighborhood_latitude = neighborhoods.loc[0, 'Latitude'] # neighborhood latitude value\nneighborhood_longitude = neighborhoods.loc[0, 'Longitude'] # neighborhood longitude value\n\nneighborhood_name = neighborhoods.loc[0, 'Neighborhood'] # neighborhood name\n\nprint('Latitude and longitude values of {} are {}, {}.'.format(neighborhood_name, \n                                                               neighborhood_latitude, \n                                                               neighborhood_longitude))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "First, let's create the GET request URL. Name your URL **url**."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "LIMIT = 100 # limit of number of venues returned by Foursquare API\nradius = 500 # define radius\n# create URL\nurl = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n    CLIENT_ID, \n    CLIENT_SECRET, \n    VERSION, \n    neighborhood_latitude, \n    neighborhood_longitude, \n    radius, \n    LIMIT)\nurl # display URL"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\nresults = requests.get(url).json()\n# results"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "From the Foursquare lab in the previous module, we know that all the information is in the *items* key. Before we proceed, let's borrow the **get_category_type** function from the Foursquare lab."
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "Now that we have the GeoJSON file, let's create a San Francisco map, centered around **[0, 0]** *latitude* and *longitude* values, with an intial zoom level of 2, and using *Mapbox Bright* style."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# function that extracts the category of the venue\ndef get_category_type(row):\n    try:\n        categories_list = row['categories']\n    except:\n        categories_list = row['venue.categories']\n        \n    if len(categories_list) == 0:\n        return None\n    else:\n        return categories_list[0]['name']"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now we are ready to clean the json and structure it into a *pandas* dataframe."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "venues = results['response']['groups'][0]['items']\n    \nnearby_venues = json_normalize(venues) # flatten JSON\n\n# filter columns\nfiltered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\nnearby_venues =nearby_venues.loc[:, filtered_columns]\n\n# filter the category for each row\nnearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n\n# clean columns\nnearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n\nnearby_venues.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print('{} venues were returned by Foursquare.'.format(nearby_venues.shape[0]))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Let's create a function to repeat the same process to all the neighborhoods in San Francisco"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "sf_venues = getNearbyVenues(names=neighborhoods['Neighborhood'],\n                                   latitudes=neighborhoods['Latitude'],\n                                   longitudes=neighborhoods['Longitude']\n                                  )\n\nsf_venues.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(sf_venues.shape)\nsf_venues.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let's check how many venues were returned for each neighborhood"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": false
            },
            "outputs": [],
            "source": "sf_venues.groupby('Neighborhood').count()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Let's find out how many unique categories can be curated from all the returned venues"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print('There are {} uniques categories.'.format(len(sf_venues['Venue Category'].unique())))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Analyze Each Neighborhood"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# one hot encoding\nsf_onehot = pd.get_dummies(sf_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add neighborhood column back to dataframe\nsf_onehot['Neighborhood'] = sf_venues['Neighborhood'] \n\n# move neighborhood column to the first column\nfixed_columns = [sf_onehot.columns[-1]] + list(sf_onehot.columns[:-1])\nsf_onehot = sf_onehot[fixed_columns]\n\nsf_onehot.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "And let's examine the new dataframe size."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "sf_onehot.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Next, let's group rows by neighborhood and by taking the mean of the frequency of occurrence of each category"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "sf_grouped = sf_onehot.groupby('Neighborhood').mean().reset_index()\nsf_grouped"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "sf_grouped.shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Let's print each neighborhood along with the top 5 most common venues"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "num_top_venues = 5\n\nfor hood in sf_grouped['Neighborhood']:\n    print(\"----\"+hood+\"----\")\n    temp = sf_grouped[sf_grouped['Neighborhood'] == hood].T.reset_index()\n    temp.columns = ['venue','freq']\n    temp = temp.iloc[1:]\n    temp['freq'] = temp['freq'].astype(float)\n    temp = temp.round({'freq': 2})\n    print(temp.sort_values('freq', ascending=False).reset_index(drop=True).head(num_top_venues))\n    print('\\n')"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "First, let's write a function to sort the venues in descending order."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now let's create the new dataframe and display the top 10 venues for each neighborhood."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "num_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighborhood'] = sf_grouped['Neighborhood']\n\nfor ind in np.arange(sf_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(sf_grouped.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Run *k*-means to cluster the neighborhood into 5 clusters."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# set number of clusters\nkclusters = 5\n\nsf_grouped_clustering = sf_grouped.drop('Neighborhood', 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(sf_grouped_clustering)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:10] "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Let's create a new dataframe that includes the cluster as well as the top 10 venues for each neighborhood."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# add clustering labels\nneighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n\nsf_merged = neighborhoods\n\n# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\nsf_merged = sf_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n\nsf_merged.head() # check the last columns!"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "address = 'San Francisco, USA'\n\ngeolocator = Nominatim(user_agent=\"ny_explorer\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinate of Downtown Toronto are {}, {}.'.format(latitude, longitude))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Finally, let's visualize the resulting clusters"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "# create map\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=12)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(sf_merged['Latitude'], sf_merged['Longitude'], sf_merged['Neighborhood'], sf_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## 5. Examine Clusters"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Now, you can examine each cluster and determine the discriminating venue categories that distinguish each cluster. Based on the defining categories, you can then assign a name to each cluster. I will leave this exercise to you."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Cluster 1"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "sf_merged.loc[sf_merged['Cluster Labels'] == 0, sf_merged.columns[[1] + list(range(5, sf_merged.shape[1]))]]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Cluster 2"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "sf_merged.loc[sf_merged['Cluster Labels'] == 1, sf_merged.columns[[1] + list(range(5, sf_merged.shape[1]))]]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Cluster 3"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "sf_merged.loc[sf_merged['Cluster Labels'] == 2, sf_merged.columns[[1] + list(range(5, sf_merged.shape[1]))]]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Cluster 4"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "sf_merged.loc[sf_merged['Cluster Labels'] == 3, sf_merged.columns[[1] + list(range(5, sf_merged.shape[1]))]]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Cluster 5"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "sf_merged.loc[sf_merged['Cluster Labels'] == 4, sf_merged.columns[[1] + list(range(5, sf_merged.shape[1]))]]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Choropleth Maps <a id=\"8\"></a>\n\nCreate `Choropleth` maps for crime rate and display clustered venues markers on top. "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "#!pip install folium\nimport folium\n\nsf_geo = r'SF_Find_Neighborhoods.geojson' # geojson file\n\nsanfran_map = folium.Map(location=[latitude, longitude], zoom_start=12)\n\nthreshold_scale = np.linspace(df_pd['Count'].min(),\n                              df_pd['Count'].max(),\n                              6, dtype=int)\nthreshold_scale = threshold_scale.tolist() # change the numpy array to a list\nthreshold_scale[-1] = threshold_scale[-1] + 1 # make sure that the last value of the list is greater than the maximum immigration\n\nsanfran_map.choropleth(\n    geo_data=sf_geo,\n    data=df_pd,\n    columns=['Neighborhood', 'Count'],\n    key_on='feature.properties.name',\n    threshold_scale=threshold_scale,\n    fill_color='YlOrRd', \n    fill_opacity=0.7, \n    line_opacity=0.2,\n    legend_name='Crime Rate in San Francisco'\n)\n\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(sf_merged['Latitude'], sf_merged['Longitude'], sf_merged['Neighborhood'], sf_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(sanfran_map)\n      \nsanfran_map"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import re\n\ndef findNeighbors(keys, neighbor):\n    for key in keys:\n        # print('%s in (%s)' % (key.lower(), neighbor.lower()))\n        if key.lower() in neighbor.lower():\n            return key"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Collect craigslist rental posts and scrape the data needed for the later analysis.\nMarker's popup lable is constucted here."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "!pip install python-craigslist --upgrade"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "from craigslist import CraigslistHousing\ncl_h = CraigslistHousing(site='sfbay', area='sfc', category='sfc/apa',\n                         filters={'max_price': 5000, 'min_price': 1000, \n                                  # 'min_bedrooms':1,  'min_bathrooms':1, 'min_ft2': 600, 'private_bath': True, \n                                  'private_room': True})\n\nresults = cl_h.get_results(sort_by='newest', geotagged=True, limit=3000)\n\nkeys = neighborhoods['Neighborhood'].tolist() \n\n# define the dataframe columns\ncolumn_names = ['Labels', 'Datetime', 'Price', 'Neighborhood', 'Latitude', 'Longitude'] \n\n# instantiate the dataframe\nhouses = pd.DataFrame(columns=column_names)    \n        \nfor result in results:\n    # print(result)\n    house_price = result['price']\n    house_date = result['datetime']\n    labels = '(%s) %s: %s' % (result['price'], result['datetime'], result['url'])\n   # print(house_name)       \n    house_latlon = result['geotag']\n    if house_latlon is None: # skip no location data \n        continue\n    # print(house_latlon)\n    house_lat = house_latlon[0]\n    house_lon = house_latlon[1]    \n    \n    tmp_name = result['where'] \n    if tmp_name is None: # skip no label for neighborhood data\n        continue\n    house_name = findNeighbors(keys, tmp_name)\n    # print(house_name)\n    if house_name is None: # skip no label for neighborhood data\n        continue\n    \n    houses = houses.append({'Labels': labels,\n                            'Datetime':house_date,\n                            'Price': house_price[1:],\n                            'Neighborhood': house_name,\n                            'Latitude': house_lat,\n                            'Longitude': house_lon}, ignore_index=True)\n    \nhouses.head()\n\n# {\n#     'id': '7087525506', \n#     'repost_of': None, \n#     'name': '2Bd 1 Ba in 4Bd 2Ba Apartment', \n#     'url': 'https://sfbay.craigslist.org/sfc/roo/d/san-francisco-2bd-1-ba-in-4bd-2ba/7087525506.html', \n#     'datetime': '2020-03-04 20:46', \n#     'last_updated': '2020-03-04 20:46', \n#     'price': '$4000', \n#     'where': 'marina / cow hollow', \n#     'has_image': True, \n#     'geotag': (37.80558, -122.420139)\n# }"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "houses.tail()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Save into csv\nhouses.to_csv('rent.csv')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "houses.dtypes\nhouses[\"Price\"] = houses[\"Price\"].astype(int) # change data type to int"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# houses = pd.read_csv('rent.csv')\nhouses.tail()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Count how many posts in each neighborhood"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "dfhm= houses.groupby('Neighborhood',as_index= False).mean()\n# dfhm = dfhm.drop(['Count'], axis=1)\nhouses['Count'] = houses.sum(axis=1)\nhouses['Count'] = 1\ndfhm.tail()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "dfh = houses[['Neighborhood','Count']]\ndfhs= dfh.groupby('Neighborhood',as_index= False).sum()\ndfhn = pd.merge(dfhm, dfhs, on='Neighborhood')\ndfhn.tail()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Remove all posts outside San Francisco neighborhoods"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": false
            },
            "outputs": [],
            "source": "keys = neighborhoods['Neighborhood'].tolist() \n# print(keys)\n# Pick up only SF neighborhoods\ndfhf = houses[houses.Neighborhood.str.contains('|'.join(keys), case=False, regex=True)].reset_index(drop=True)\ndfhf.tail()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Rent price statistics"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import seaborn as sns\nsns.distplot(dfhf['Price'],bins=20)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "import matplotlib.pyplot as plt\nplt.figure(figsize=(20,6))\nplt.xticks(rotation='vertical')\nsns.boxplot(x='Neighborhood', y='Price', data=dfhf)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "dfha = dfhn[dfhn.Neighborhood.str.contains('|'.join(keys), case=False, regex=True)].reset_index(drop=True)\ndfha#.tail()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Display mean rent price in Choropleth map imposing with a venue marker."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "sf_geo = r'SF_Find_Neighborhoods.geojson' # geojson file\n\nsanfran_map = folium.Map(location=[latitude, longitude], zoom_start=12)\n\nthreshold_scale = np.linspace(dfha['Price'].min(),\n                              dfha['Price'].max(),\n                              6, dtype=int)\nthreshold_scale = threshold_scale.tolist() # change the numpy array to a list\nthreshold_scale[-1] = threshold_scale[-1] + 1 # make sure that the last value of the list is greater than the maximum immigration\n\nsanfran_map.choropleth(\n    geo_data=sf_geo,\n    data=dfha,\n    columns=['Neighborhood', 'Price'],\n    key_on='feature.properties.name',\n    threshold_scale=threshold_scale,\n    fill_color='GnBu', \n    fill_opacity=0.7, \n    line_opacity=0.2,\n    legend_name='Mean Value for Rent in San Francisco'\n)\n\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(sf_merged['Latitude'], sf_merged['Longitude'], sf_merged['Neighborhood'], sf_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(sanfran_map)\n       \nsanfran_map"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Limit the number of posts to 100 in the map"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "limit = 100 # limit newest posted ads only display in map\nnewRents = houses.iloc[0:limit, :]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Display the newest 100 craigslist posts and venue type on top of crime rate Choropleth map."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "sf_geo = r'SF_Find_Neighborhoods.geojson' # geojson file\n\nsanfran_map = folium.Map(location=[latitude, longitude], zoom_start=12)\n\nthreshold_scale = np.linspace(df_pd['Count'].min(),\n                              df_pd['Count'].max(),\n                              6, dtype=int)\nthreshold_scale = threshold_scale.tolist() # change the numpy array to a list\nthreshold_scale[-1] = threshold_scale[-1] + 1 # make sure that the last value of the list is greater than the maximum immigration\n\nsanfran_map.choropleth(\n    geo_data=sf_geo,\n    data=df_pd,\n    columns=['Neighborhood', 'Count'],\n    key_on='feature.properties.name',\n    threshold_scale=threshold_scale,\n    fill_color='YlOrRd', \n    fill_opacity=0.7, \n    line_opacity=0.2,\n    legend_name='Crime Rate in San Francisco'\n)\n\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(sf_merged['Latitude'], sf_merged['Longitude'], sf_merged['Neighborhood'], sf_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(sanfran_map)\n      \nfrom folium import plugins\n# instantiate a mark cluster object for the incidents in the dataframe\nhs = plugins.MarkerCluster().add_to(sanfran_map)\n\n# loop through the dataframe and add each data point to the mark cluster\nfor lat, lng, label, in zip(newRents.Latitude, newRents.Longitude, newRents.Labels):\n    folium.Marker(\n        location=[lat, lng],\n        icon=folium.Icon(color='green', icon='info-sign'),\n        popup=label,\n    ).add_to(hs)\n\n# display map\nsanfran_map"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "button": false,
                "new_sheet": false,
                "run_control": {
                    "read_only": false
                }
            },
            "source": "<hr>\n\nCopyright &copy; 2020. This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/)."
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        },
        "widgets": {
            "state": {},
            "version": "1.1.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}